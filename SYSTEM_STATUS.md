# System Status - Ijon RAG System

Last Updated: 2025-07-04

## ‚úÖ Current Production Configuration

### Core Architecture
- **Embeddings**: Gemini text-embedding-004 (768 dimensions)
- **Vector Database**: Neon PostgreSQL with pgvector extension
- **Context Enhancement**: SmartContextEnhancer with mental model detection
- **Query System**: Direct pgvector similarity search

### API Connections
- ‚úÖ **Gemini API**: Connected and working
- ‚úÖ **Neon Database**: Connected with pgvector enabled
- ‚ö†Ô∏è  **OpenAI API**: Available but not actively used (legacy)
- ‚ö†Ô∏è  **Pinecone**: Available but not actively used (migrated to Neon)

### Database Schema
```sql
-- Main tables with Gemini embeddings
content_chunks:
  - embedding_gemini: vector(768)
  - embedding_model: text
  - content: text
  - metadata: jsonb

documents:
  - title: text
  - file_path: text
  - processed_at: timestamp
```

## üìä Current Data

### Processed Documents
1. **Flow: The Psychology of Optimal Experience** - COMPLETE (317 pages)
   - Full text extracted and embedded
   - Enhanced with smart context
   - Searchable via `query_mental_models.py`

### Data Statistics
- **Total Chunks**: ~1,500 from Flow book
- **Average Chunk Size**: ~500 tokens
- **Embedding Cost**: ~$0.04 for complete book
- **Storage per Embedding**: ~9.5KB (text transfer format)

## üöÄ Active Components

### Processing Pipeline
1. **PDF Processor**: `src/pdf_processor/` - PyPDF2/PyMuPDF
2. **Context Enhancer**: `src/context/smart_context_enhancer.py`
3. **Embedder**: `src/rag/gemini_embedder.py`
4. **Storage**: Direct SQL insert to Neon

### Query Pipeline
1. **Query Interface**: `query_mental_models.py`
2. **Context Enhancement**: Same as processing
3. **Vector Search**: pgvector `<->` operator
4. **Result Ranking**: By distance score

## üîß Configuration Files

### Active
- `.env` - Environment variables (GEMINI_API_KEY, DATABASE_URL)
- `requirements.txt` - Core dependencies
- `CLAUDE.md` - AI assistant instructions

### Legacy (To Be Updated)
- `src/config.py` - Still references OpenAI as default
- Various test configurations

## üß™ Testing

### Working Tests
```bash
python test_neon_connection.py      # ‚úÖ Database connection
python test_gemini_embeddings.py    # ‚úÖ Embedding generation  
python query_mental_models.py demo  # ‚úÖ Query system
```

### Integration Tests
```bash
python test_system.py               # ‚ö†Ô∏è  May need updates for Gemini
python -m pytest tests/             # ‚ö†Ô∏è  Some tests assume OpenAI
```

## üöß Known Issues

1. **Multiple Processing Scripts**: 20+ experimental variants need cleanup
2. **Legacy Code**: OpenAI embedding code still present in `src/rag/embedder.py`
3. **Incomplete Books**: Previously processed books limited to 100 pages
4. **Test Coverage**: Some tests still assume OpenAI embeddings

## üìà Performance Metrics

### Processing Speed
- **PDF Extraction**: ~1 second per page
- **Context Enhancement**: ~0.5 seconds per chunk
- **Embedding Generation**: ~1-2 seconds per page
- **Total**: ~3-4 seconds per page end-to-end

### Query Performance
- **Query Enhancement**: ~100ms
- **Embedding Generation**: ~500ms
- **Vector Search**: ~50ms
- **Total Response**: ~700ms average

### Cost Analysis
- **Embedding Cost**: ~$0.025 per million tokens
- **Average Book**: ~$0.04-0.10 depending on size
- **Query Cost**: ~$0.0001 per query

## üîÆ Experimental Features (R&D)

### Cognitive RAG Pipeline
- Location: `src/rag/cognitive_pipeline.py`
- Status: Experimental, not in production
- Features: Agent-based routing for complex queries

### 12-Factor Extraction
- Location: `extraction/v2/`
- Status: Experimental, follows best practices
- Features: Quality scoring, human validation, error handling

### Knowledge Graph
- Location: `src/knowledge_graph/`, `src/graph_db/`
- Status: Partially implemented, not active
- Features: Entity extraction, relationship mapping

## üìù Next Steps

1. **Code Cleanup**: Remove experimental processing scripts
2. **Update Config**: Set Gemini as default in `src/config.py`
3. **Test Updates**: Update tests to use Gemini embeddings
4. **Documentation**: Keep README.md current with changes
5. **Process More Books**: Add remaining mental models books